{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kIWaR5ZpKlJ"
   },
   "source": [
    "## Dog Breed Classification\n",
    "\n",
    "In this project we will use traditional CNN, CNN with data augmentation and finally transfer Learning by VGG16 model with weights pre-trained on Imagenet to solve the dog breed classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZWpQv1OwqYK"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxPS5wEMOsji"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "N_8lCpsYreTv",
    "outputId": "58ce7014-07bd-41f5-8476-389a1d214b93"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "#from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pV7G2w0fNsyJ",
    "outputId": "b4702d87-8cfe-4924-e50e-93d6d9384e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F7MDmaAw2xGO"
   },
   "source": [
    "### Load Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-OfNYMfNo8X"
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/content/drive/My Drive/R8_CV_Project2/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "fVhB9OopxFbX",
    "outputId": "3f591835-91f5-4b85-c1bc-84a68eccfc11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PCQM6NljPB7w",
    "outputId": "0b95bde2-b09b-4d80-b5f0-7656375044d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(labels.breed).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1q2zzIaUprk_"
   },
   "source": [
    "Now, upload the given dataset file shared with you in your google drive and give its path for the below given `project_path` variable. For example, a path is given below according to the file path in our google drive. You need to change this to match the path of yours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tp6FvAToxUFs"
   },
   "outputs": [],
   "source": [
    "project_path = \"/content/drive/My Drive/R8_CV_Project2/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rydR_j8lqUei"
   },
   "source": [
    "Run the below code to extract all the images in the train.zip files given in the dataset. We are going to use these images as train and validation sets and their labels in further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3350WZM4w4EL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir('/content/drive/My Drive/R8_CV_Project2/train')\n",
    "\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(project_path+'train.zip', 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3NHq1iBCfFjE"
   },
   "source": [
    "Repeat the same step for test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fxzynvB2YCb"
   },
   "outputs": [],
   "source": [
    "#os.chdir('/content/drive/My Drive/R8_CV_Project2/test')\n",
    "\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(project_path+'test.zip', 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jnUMhQrDfJmz"
   },
   "source": [
    "Repeat the same step for sample_submission.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PyTxE8q2jLf"
   },
   "outputs": [],
   "source": [
    "#not required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2G9RIxB-fOLT"
   },
   "source": [
    "Repeat the same step for labels.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rXtnEoEixbgi"
   },
   "outputs": [],
   "source": [
    "#not required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sJc1lVrW_jmL"
   },
   "source": [
    "After this process, we will have 4 files - Train folder, test folder and labels.csv and sample_submission.csv as part of your google drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aYmJKmDqqpng"
   },
   "source": [
    "### Read labels.csv file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "WmlJ2VMY96IZ",
    "outputId": "c1f85f79-1e4e-465d-ac54-152a015ee3f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QP8YAzQvqyK-"
   },
   "source": [
    "### Print the count of each category of Dogs given in the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "3L2naXlr96Im",
    "outputId": "a0f05aae-8307-4dbb-f174-c421ec2ef979"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scottish_deerhound      126\n",
      "maltese_dog             117\n",
      "afghan_hound            116\n",
      "entlebucher             115\n",
      "bernese_mountain_dog    114\n",
      "                       ... \n",
      "golden_retriever         67\n",
      "komondor                 67\n",
      "brabancon_griffon        67\n",
      "eskimo_dog               66\n",
      "briard                   66\n",
      "Name: breed, Length: 120, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_count = labels.breed.value_counts()\n",
    "print(label_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WI94_Qcc0D4M"
   },
   "source": [
    "### Get one-hot encodings of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q48iAcY196I3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder \n",
    "  \n",
    "onehotencoder = OneHotEncoder() \n",
    "data = onehotencoder.fit_transform(np.array(labels['breed']).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9nlWmRNM96I8"
   },
   "outputs": [],
   "source": [
    "data_ohe = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2o_vGre-Tqqf"
   },
   "outputs": [],
   "source": [
    "data_ohe.columns = onehotencoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "aEXIKRLYTxkL",
    "outputId": "7191173e-e17a-4294-e3ae-ceb6e2b608e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>beagle</th>\n",
       "      <th>bedlington_terrier</th>\n",
       "      <th>bernese_mountain_dog</th>\n",
       "      <th>black-and-tan_coonhound</th>\n",
       "      <th>blenheim_spaniel</th>\n",
       "      <th>bloodhound</th>\n",
       "      <th>bluetick</th>\n",
       "      <th>border_collie</th>\n",
       "      <th>border_terrier</th>\n",
       "      <th>borzoi</th>\n",
       "      <th>boston_bull</th>\n",
       "      <th>bouvier_des_flandres</th>\n",
       "      <th>boxer</th>\n",
       "      <th>brabancon_griffon</th>\n",
       "      <th>briard</th>\n",
       "      <th>brittany_spaniel</th>\n",
       "      <th>bull_mastiff</th>\n",
       "      <th>cairn</th>\n",
       "      <th>cardigan</th>\n",
       "      <th>chesapeake_bay_retriever</th>\n",
       "      <th>chihuahua</th>\n",
       "      <th>chow</th>\n",
       "      <th>clumber</th>\n",
       "      <th>cocker_spaniel</th>\n",
       "      <th>collie</th>\n",
       "      <th>curly-coated_retriever</th>\n",
       "      <th>dandie_dinmont</th>\n",
       "      <th>dhole</th>\n",
       "      <th>dingo</th>\n",
       "      <th>doberman</th>\n",
       "      <th>english_foxhound</th>\n",
       "      <th>...</th>\n",
       "      <th>norwegian_elkhound</th>\n",
       "      <th>norwich_terrier</th>\n",
       "      <th>old_english_sheepdog</th>\n",
       "      <th>otterhound</th>\n",
       "      <th>papillon</th>\n",
       "      <th>pekinese</th>\n",
       "      <th>pembroke</th>\n",
       "      <th>pomeranian</th>\n",
       "      <th>pug</th>\n",
       "      <th>redbone</th>\n",
       "      <th>rhodesian_ridgeback</th>\n",
       "      <th>rottweiler</th>\n",
       "      <th>saint_bernard</th>\n",
       "      <th>saluki</th>\n",
       "      <th>samoyed</th>\n",
       "      <th>schipperke</th>\n",
       "      <th>scotch_terrier</th>\n",
       "      <th>scottish_deerhound</th>\n",
       "      <th>sealyham_terrier</th>\n",
       "      <th>shetland_sheepdog</th>\n",
       "      <th>shih-tzu</th>\n",
       "      <th>siberian_husky</th>\n",
       "      <th>silky_terrier</th>\n",
       "      <th>soft-coated_wheaten_terrier</th>\n",
       "      <th>staffordshire_bullterrier</th>\n",
       "      <th>standard_poodle</th>\n",
       "      <th>standard_schnauzer</th>\n",
       "      <th>sussex_spaniel</th>\n",
       "      <th>tibetan_mastiff</th>\n",
       "      <th>tibetan_terrier</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  affenpinscher afghan_hound  ... wire-haired_fox_terrier yorkshire_terrier\n",
       "0           0.0          0.0  ...                     0.0               0.0\n",
       "1           0.0          0.0  ...                     0.0               0.0\n",
       "2           0.0          0.0  ...                     0.0               0.0\n",
       "3           0.0          0.0  ...                     0.0               0.0\n",
       "4           0.0          0.0  ...                     0.0               0.0\n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWaJ9naXfoiU"
   },
   "source": [
    "## Preparing training dataset\n",
    "1. Write a code which reads each and every id from labels.csv file and loads the corresponding image (in RGB - 128, 128, 3) from the train folder. <br>\n",
    "2. Create 2 variables <br> \n",
    "     a.  x_train - Should have all the images of the dogs from train folder <br>\n",
    "     b.  y_train - Corresponding label of the dog <br>\n",
    "<u>Note:</u> The id of the dog images and its corresponding labels are available in labels.csv file   \n",
    "<u>Hint:</u> Watch the video shared on \"Preparing the training dataset\" if you face issue on creating the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aC2f9ecR0XGR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "basepath2 = '/content/train/'\n",
    "files2 = []\n",
    "for entry in os.listdir(basepath2):\n",
    "    if os.path.isfile(os.path.join(basepath2, entry)):\n",
    "        files2.append(entry)\n",
    "\n",
    "#if fle.is_dir() is False:\n",
    "#    with train_imgArchive.open(fle) as file:\n",
    "#            img = Image.open(file)\n",
    "#            #PIL image is saved as an png image, to convert it in to an array, we use np.array(image)\n",
    "#            x_train.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "O0-ZAlrc-Tw3",
    "outputId": "eb1b79b0-0716-4733-8978-7b077c4af9d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10222"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rGKR_CEmIaxd"
   },
   "outputs": [],
   "source": [
    "im_width = 128\n",
    "im_height = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zlNVRUhIAdz"
   },
   "outputs": [],
   "source": [
    "# Initializing an empty array for storing the image arrays\n",
    "X = np.zeros((len(files2), im_height, im_width, 3), dtype=np.float32)\n",
    "#y = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8DOFvk8SgHn"
   },
   "outputs": [],
   "source": [
    "label_count=0\n",
    "for fle_name in labels.id:\n",
    "  img = load_img(basepath2 + fle_name+'.jpg')\n",
    "  x_img = img_to_array(img)\n",
    "  x_img = resize(x_img, (128, 128, 3))\n",
    "  X[label_count] = x_img/255\n",
    "  label_count = label_count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "C8z52hB8AVb4",
    "outputId": "c886d46e-8002-4a7d-d681-4e0559bed6b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images read:  10222\n"
     ]
    }
   ],
   "source": [
    "print('Number of images read: ', label_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ioWDEgElBOs"
   },
   "source": [
    "Normalize the training data and convert into 4 dimensions so that it can be used as an input to conv layers in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "Vm7YXvJDjYK9",
    "outputId": "11b5fb3d-a387-4c2e-8c24-e167d29150e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Data: \n",
      " [[[0.6329613  0.416235   0.23339635]\n",
      "  [0.6546272  0.48126888 0.27316448]\n",
      "  [0.72479945 0.5730192  0.33029   ]\n",
      "  ...\n",
      "  [0.8743123  0.75024456 0.4383268 ]\n",
      "  [0.84531367 0.73586744 0.34079024]\n",
      "  [0.74472696 0.6219113  0.29560798]]\n",
      "\n",
      " [[0.49541402 0.3334337  0.19406752]\n",
      "  [0.73178804 0.5922641  0.43648228]\n",
      "  [0.7094787  0.569876   0.4016111 ]\n",
      "  ...\n",
      "  [0.79920834 0.63772583 0.3418426 ]\n",
      "  [0.8415002  0.70436615 0.3785822 ]\n",
      "  [0.8570511  0.7222736  0.32488644]]\n",
      "\n",
      " [[0.5723346  0.40296352 0.2310809 ]\n",
      "  [0.60172164 0.43072847 0.25283983]\n",
      "  [0.57591003 0.3905361  0.22937353]\n",
      "  ...\n",
      "  [0.74658734 0.5496322  0.21058485]\n",
      "  [0.74975026 0.59366775 0.29637325]\n",
      "  [0.8091298  0.6526616  0.25705042]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.7382106  0.46416953 0.29341644]\n",
      "  [0.73367476 0.47818902 0.2662934 ]\n",
      "  [0.7205014  0.48173937 0.26516196]\n",
      "  ...\n",
      "  [0.62749165 0.35807723 0.27470735]\n",
      "  [0.60369873 0.35637015 0.23437205]\n",
      "  [0.7071898  0.5005505  0.33869168]]\n",
      "\n",
      " [[0.72698545 0.4645318  0.25721878]\n",
      "  [0.7377348  0.48113358 0.27764562]\n",
      "  [0.7326588  0.48697948 0.29018766]\n",
      "  ...\n",
      "  [0.55424565 0.28677297 0.23290294]\n",
      "  [0.64773214 0.42873654 0.27667564]\n",
      "  [0.8592852  0.64987934 0.4603435 ]]\n",
      "\n",
      " [[0.7238587  0.46146443 0.25396907]\n",
      "  [0.74204344 0.4854435  0.28200105]\n",
      "  [0.74037325 0.49466896 0.29798338]\n",
      "  ...\n",
      "  [0.50697345 0.21846123 0.19563533]\n",
      "  [0.5560635  0.30038056 0.18102032]\n",
      "  [0.7715996  0.5628424  0.34911975]]]\n"
     ]
    }
   ],
   "source": [
    "# data is already normalized in the above step.\n",
    "print('Normalized Data: \\n',X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdCXuAE11gZL"
   },
   "source": [
    "### Split the training and validation data from `x_train_data` and `y_train_data` obtained from above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kpWx-pgV96Jv"
   },
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(X, data_ohe, train_size = 0.8, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "UQ7q7AyoH3ie",
    "outputId": "d2b49224-759b-4c51-97bd-62d881302abf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8177, 128, 128, 3)\n",
      "(8177, 120)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "6RSLU1ZpWCR0",
    "outputId": "34a1122f-2a84-4011-94e9-de9e7e1cfa6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2045, 128, 128, 3)\n",
      "(2045, 120)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XkL-N1jDsU8m"
   },
   "source": [
    "### Loading the test data\n",
    "Read the id column from the samples_submission.csv and store it in test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DnpXdpd9b3E7"
   },
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv('/content/drive/My Drive/R8_CV_Project2/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uw85YrSYWgQ5"
   },
   "outputs": [],
   "source": [
    "test_img = sample_sub.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEJqZIMbm0Jo"
   },
   "source": [
    "Run the below code to load the test image files in x_test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zf7n4WG-b3Hv"
   },
   "outputs": [],
   "source": [
    "#x_test_feature = []\n",
    "#i = 0 # initialisation\n",
    "#for f in tqdm(test_img.values): # f for format ,jpg\n",
    "#    img = cv2.imread('./test/{}.jpg'.format(f), 0)\n",
    "#    img_resize = cv2.resize(img, (img_rows, img_cols)) \n",
    "#    x_test_feature.append(img_resize)\n",
    "\n",
    "#mport os\n",
    "basepath = '/content/test/'\n",
    "files = []\n",
    "for entry in os.listdir(basepath):\n",
    "    if os.path.isfile(os.path.join(basepath, entry)):\n",
    "        files.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N07QQw2UFWdB"
   },
   "outputs": [],
   "source": [
    "x_test_feature = np.zeros((len(files), im_height, im_width, 3), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fwHMxV5zFVPW"
   },
   "outputs": [],
   "source": [
    "tst_label_count=0\n",
    "for tst_fle_name in test_img:\n",
    "  img_tst = load_img(basepath + tst_fle_name+'.jpg')\n",
    "  x_tst_img = img_to_array(img_tst)\n",
    "  x_tst_img = resize(x_tst_img, (128, 128, 3))\n",
    "  x_test_feature[label_count] = x_tst_img/255\n",
    "  tst_label_count = tst_label_count+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9My6qSyDnE-_"
   },
   "source": [
    "Normalize the test data and convert it into 4 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mgXe64pmFJNN",
    "outputId": "4b06e399-d9f1-49c9-d2b0-87f5c5d010af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10357"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93n-IntMnJGI"
   },
   "outputs": [],
   "source": [
    "#Data is already normalized while reading the data in the above step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKezNJVMsocP"
   },
   "source": [
    "### Build a basic conv neural network with 2 conv layers (kernel sizes - 5 and 3) add layers as mentioned below for classification.\n",
    "\n",
    "1. Add a Dense layer with 256 neurons with `relu` activation\n",
    "\n",
    "2. Add a Dense layer with 120 neurons as final layer (as there are 120 classes in the given dataset) with `softmax` activation for classifiaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SRDHSo7jCXw0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D2jxTY2S96J4"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape = (128,128,3)))\n",
    "model.add(Conv2D(input_shape=(128,128,3),filters=64,kernel_size=(5,5),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=256,activation=\"relu\"))\n",
    "model.add(Dense(units=120, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_BAvCzo96J6"
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Store Training Results\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
    "callback_list = [early_stopping]# [stats, early_stopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ui8EXw6_oqpR"
   },
   "source": [
    "### Use batch_size = 128 and epochs = 10 and execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "colab_type": "code",
    "id": "IriIc37NozbK",
    "outputId": "62295931-9920-4aff-b237-47de32e8f0ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8177 samples, validate on 2045 samples\n",
      "Epoch 1/10\n",
      "8177/8177 [==============================] - 5s 553us/step - loss: 0.0166 - acc: 0.9994 - val_loss: 9.3290 - val_acc: 0.0631\n",
      "Epoch 2/10\n",
      "8177/8177 [==============================] - 4s 532us/step - loss: 0.0164 - acc: 0.9993 - val_loss: 9.3711 - val_acc: 0.0631\n",
      "Epoch 3/10\n",
      "8177/8177 [==============================] - 4s 532us/step - loss: 0.0120 - acc: 0.9996 - val_loss: 9.4723 - val_acc: 0.0636\n",
      "Epoch 4/10\n",
      "8177/8177 [==============================] - 4s 533us/step - loss: 0.0146 - acc: 0.9993 - val_loss: 9.4986 - val_acc: 0.0631\n",
      "Epoch 5/10\n",
      "8177/8177 [==============================] - 4s 533us/step - loss: 0.0128 - acc: 0.9994 - val_loss: 9.5642 - val_acc: 0.0645\n",
      "Epoch 6/10\n",
      "8177/8177 [==============================] - 4s 533us/step - loss: 0.0115 - acc: 0.9994 - val_loss: 9.5956 - val_acc: 0.0645\n",
      "Epoch 7/10\n",
      "8177/8177 [==============================] - 4s 534us/step - loss: 0.0100 - acc: 0.9995 - val_loss: 9.6620 - val_acc: 0.0621\n",
      "Epoch 8/10\n",
      "8177/8177 [==============================] - 4s 535us/step - loss: 0.0099 - acc: 0.9995 - val_loss: 9.7191 - val_acc: 0.0650\n",
      "Epoch 9/10\n",
      "8177/8177 [==============================] - 4s 535us/step - loss: 0.0094 - acc: 0.9995 - val_loss: 9.7698 - val_acc: 0.0621\n",
      "Epoch 10/10\n",
      "8177/8177 [==============================] - 4s 533us/step - loss: 0.0094 - acc: 0.9995 - val_loss: 9.7749 - val_acc: 0.0636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff264a58e48>"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=128, validation_data=(X_val, y_val), callbacks=callback_list, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0PR9j5_Xozmd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z8hWaKmjoz69"
   },
   "source": [
    "#The model accuracy is very poor !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "agJKkc6xtKiq"
   },
   "source": [
    "### Use Data Augmentation in the above model to see if the accuracy improves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqTlW0qHb3Xb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sssbaTfxlkk"
   },
   "source": [
    "### Using the above objects, create the image generators with variable names `train_generator` and `val_generator`\n",
    "\n",
    "You need to use train_datagen.flow() and val_datagen.flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sehaRgT-96KQ"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5WwFjgnlNJ-"
   },
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(validation_split=0.2, \n",
    "                          rescale=1/255,\n",
    "                          samplewise_center=True, # set input mean to 0 over the sample\n",
    "                          samplewise_std_normalization=True,  # divide inputs by std of the sample\n",
    "                          rotation_range=90,       # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                          width_shift_range=0.2,   # randomly shift images horizontally (fraction of total width)\n",
    "                          height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "                          fill_mode='reflect',     # filling the area outside\n",
    "                          zoom_range=0.4,          # random zoom\n",
    "                          horizontal_flip=True,    # randomly flip images\n",
    "                          vertical_flip=True)      # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sPsKhpnclW89"
   },
   "outputs": [],
   "source": [
    "train_generator = data_gen.flow(X_train, y_train, batch_size=128)\n",
    "val_generator = data_gen.flow(X_val,y_val,batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVFQJZw3x4-C"
   },
   "source": [
    "### Fit the model using fit_generator() using `train_generator` and `val_generator` from the above step with 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "J1K2MqHbuPUa",
    "outputId": "c625acf2-bc11-4551-cfc4-113b895bba6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 38s - loss: 6.9976 - acc: 0.0248 - val_loss: 5.9700 - val_acc: 0.0165\n",
      "Epoch 2/10\n",
      " - 35s - loss: 4.7921 - acc: 0.0215 - val_loss: 5.0160 - val_acc: 0.0174\n",
      "Epoch 3/10\n",
      " - 36s - loss: 4.7475 - acc: 0.0211 - val_loss: 4.8348 - val_acc: 0.0177\n",
      "Epoch 4/10\n",
      " - 38s - loss: 4.7138 - acc: 0.0199 - val_loss: 4.8259 - val_acc: 0.0200\n",
      "Epoch 5/10\n",
      " - 34s - loss: 4.7044 - acc: 0.0180 - val_loss: 4.7733 - val_acc: 0.0193\n",
      "Epoch 6/10\n",
      " - 34s - loss: 4.6859 - acc: 0.0201 - val_loss: 4.7418 - val_acc: 0.0229\n",
      "Epoch 7/10\n",
      " - 35s - loss: 4.6180 - acc: 0.0281 - val_loss: 4.7375 - val_acc: 0.0240\n",
      "Epoch 8/10\n",
      " - 35s - loss: 4.6343 - acc: 0.0305 - val_loss: 4.7179 - val_acc: 0.0254\n",
      "Epoch 9/10\n",
      " - 36s - loss: 4.6310 - acc: 0.0290 - val_loss: 4.6991 - val_acc: 0.0266\n",
      "Epoch 10/10\n",
      " - 35s - loss: 4.6136 - acc: 0.0273 - val_loss: 4.6745 - val_acc: 0.0248\n"
     ]
    }
   ],
   "source": [
    "output_imggen = model1.fit_generator(train_generator, epochs=10, validation_data=val_generator, verbose = 2, steps_per_epoch=20, validation_steps=80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2zmLztqo5DY"
   },
   "source": [
    "# Model accuracy is still poor!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rSTATrhsAo7L"
   },
   "source": [
    "### Lets use Transfer Learning\n",
    "\n",
    "Download the vgg wieght file from here : https://github.com/MinerKasch/applied_deep_learning/blob/master/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zy5JdbW6pIvD"
   },
   "source": [
    "Use the below code to load VGG16 weights trained on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yrqs0zg7ApNw"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras import backend as K\n",
    "\n",
    "#Before prediction\n",
    "K.clear_session()\n",
    "# Instantiate the model with the pre-trained weights (no top)\n",
    "path = '/content/drive/My Drive/R8_CV_Project2/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "base_model= VGG16(weights = path, input_shape=(im_height,im_width,3), include_top=False)\n",
    "\n",
    "#After prediction\n",
    "#K.clear_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EItOlRBGpV_A"
   },
   "source": [
    "Print the summary of the base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "colab_type": "code",
    "id": "lQsEBgnlpHjH",
    "outputId": "88a7c31d-0988-4007-cf76-8ffc24cb70f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHpeOyW0qauW"
   },
   "source": [
    "### Add the following classification layers to the imported VGG Model <br>\n",
    "1. Flatten Layer\n",
    "2. Dense layer with 1024 neurons with activation as Relu\n",
    "3. Dense layer with 256 neurons with activation as Relu\n",
    "4. Dense layer with 120 neurons with activation as Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "0BpT4MLkqoaO",
    "outputId": "4bc70bd1-1a4e-4634-f151-a0438ee53b30"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "x = base_model.output\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(120, activation='softmax')(x)\n",
    "\n",
    "# Creating new model. Please note that this is NOT a Sequential() model.\n",
    "from keras.models import Model\n",
    "custom_model = Model(input=base_model.input, output=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LeQem0pHITIj"
   },
   "source": [
    "### Make all the layers in the base_model (VGG16) to be non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "colab_type": "code",
    "id": "C7w9CSPvIRnX",
    "outputId": "48f647b2-9e4b-4829-afee-b3c7d8d155b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34minput_1\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock1_conv1\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock1_conv2\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock1_pool\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock2_conv1\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock2_conv2\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock2_pool\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock3_conv1\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock3_conv2\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock3_conv3\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock3_pool\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock4_conv1\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock4_conv2\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock4_conv3\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock4_pool\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock5_conv1\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock5_conv2\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock5_conv3\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mblock5_pool\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mflatten_1\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mdense_1\u001b[0m\n",
      "\u001b[31mTrue\u001b[0m\n",
      "\u001b[34mdense_2\u001b[0m\n",
      "\u001b[31mTrue\u001b[0m\n",
      "\u001b[34mdense_3\u001b[0m\n",
      "\u001b[31mTrue\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for layer in custom_model.layers:\n",
    "  if('dense' not in layer.name): #prefix detection to freeze layers which does not have dense\n",
    "    #Freezing a layer\n",
    "    layer.trainable = False\n",
    "\n",
    "#Module to print colourful statements\n",
    "from termcolor import colored\n",
    "\n",
    "#Check which layers have been frozen \n",
    "for layer in custom_model.layers:\n",
    "  print (colored(layer.name, 'blue'))\n",
    "  print (colored(layer.trainable, 'red'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kj-BwqgfIkdv"
   },
   "source": [
    "### Fit and compile the model with batch_size = 128 and epochs = 10 and execute the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YD5fAgVQIpKZ"
   },
   "source": [
    "Try to get training and validation accuracy to be more than 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wjh2XC01sVh5"
   },
   "outputs": [],
   "source": [
    "custom_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "SZk2SWvjIoRP",
    "outputId": "cb305fc7-9c7a-4fef-a412-5db8da421892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 57s - loss: 4.7965 - acc: 0.0139 - val_loss: 4.7644 - val_acc: 0.0176\n",
      "Epoch 2/10\n",
      " - 54s - loss: 4.7124 - acc: 0.0248 - val_loss: 4.6952 - val_acc: 0.0210\n",
      "Epoch 3/10\n",
      " - 54s - loss: 4.6273 - acc: 0.0367 - val_loss: 4.6177 - val_acc: 0.0372\n",
      "Epoch 4/10\n",
      " - 55s - loss: 4.5093 - acc: 0.0504 - val_loss: 4.5243 - val_acc: 0.0523\n",
      "Epoch 5/10\n",
      " - 54s - loss: 4.3750 - acc: 0.0673 - val_loss: 4.4157 - val_acc: 0.0553\n",
      "Epoch 6/10\n",
      " - 54s - loss: 4.2475 - acc: 0.0783 - val_loss: 4.3045 - val_acc: 0.0567\n",
      "Epoch 7/10\n",
      " - 54s - loss: 4.1196 - acc: 0.0912 - val_loss: 4.1867 - val_acc: 0.0709\n",
      "Epoch 8/10\n",
      " - 54s - loss: 4.0057 - acc: 0.1043 - val_loss: 4.1148 - val_acc: 0.1007\n",
      "Epoch 9/10\n",
      " - 54s - loss: 3.9189 - acc: 0.1172 - val_loss: 4.0623 - val_acc: 0.0885\n",
      "Epoch 10/10\n",
      " - 54s - loss: 3.8422 - acc: 0.1246 - val_loss: 4.0554 - val_acc: 0.0890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff264140a58>"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.fit_generator(train_generator, epochs=10, validation_data=val_generator, verbose = 2,  steps_per_epoch=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OoXX4D2fsAr0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CV_Project2_Dog_Breed_Classification_Questions-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
